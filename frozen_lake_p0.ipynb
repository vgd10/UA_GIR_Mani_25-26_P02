{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcc233d8-6e79-4ec7-b24a-7cd06efa5333",
   "metadata": {},
   "source": [
    "# Práctica 0: Frozen Lake\n",
    "\n",
    "En este notebook trabajaremos con el entorno **Frozen Lake**, parte de la librería OpenAI Gym. Este entorno simula un lago congelado donde un agente debe aprender a llegar a su objetivo (la meta) mientras evita caer en agujeros en el hielo. Es un problema clásico de **aprendizaje por refuerzo** (Reinforcement Learning) que ilustra conceptos como:\n",
    "\n",
    "- Modelado de entornos utilizando **procesos de decisión de Markov (MDPs)**.\n",
    "- Definición de políticas y recompensas.\n",
    "- Uso de algoritmos de planificación como **Value Iteration** y **Policy Iteration**.\n",
    "\n",
    "## Descripción del entorno\n",
    "El entorno de Frozen Lake consiste en una cuadrícula de 4x4 donde cada celda puede representar uno de los siguientes estados:\n",
    "- **S** (Start): La posición inicial del agente.\n",
    "- **F** (Frozen): Una celda segura que el agente puede atravesar.\n",
    "- **H** (Hole): Un agujero en el que el agente caerá, terminando el episodio.\n",
    "- **G** (Goal): El objetivo que el agente debe alcanzar.\n",
    "\n",
    "![Escenario](https://www.gymlibrary.dev/_images/frozen_lake.gif)\n",
    "\n",
    "El agente puede moverse (acciones) en cuatro direcciones: **arriba**, **abajo**, **izquierda**, y **derecha**. Aunque el ejemplo clásico incluye el efecto de hielo resbaladizo, lo que introduce un grado de aleatoriedad en el entorno, en este ejercicio y con el objetivo de centrarnos en otros aspectos, utilizaremos la versión sin Sin embargo, debido al hielo resbaladizo, los movimientos no siempre son precisos, lo que introduce un grado de aleatoriedad en el entorno. Sin embargo, por simplificar el ejercicio, no incluiremos la parte resbaladiza.\n",
    "\n",
    "En caso de que alguno de los acciones haga que el agente salga del mapa, la acción no se llevará a cabo (y su estado no cambiará)\n",
    "\n",
    "### Acciones\n",
    "\n",
    "El agente utilizará un vector de 1 elemento para las acciones que puede realizar. En el ejercicio de **FrozenLake**, el espacio de acciones es discreto, y este puede tomar uno de los siguientes valores para decidir la dirección en la que moverse:\n",
    "\n",
    "- 0: IZQUIERDA\n",
    "\n",
    "- 1: ABAJO\n",
    "\n",
    "- 2: DERECHA\n",
    "\n",
    "- 3: ARRIBA\n",
    "\n",
    "### Estados (o espacio de observación)\n",
    "\n",
    "El modelado de estados es una parte esencial a la hora de resolver los problemas siguiendo el proceso de decisión de Markov (MDP). El estado representa la posición actual del agente. El número de estados posibles depende del mapa en este caso. Dado que tenemos un problema discreto, donde los estados posibles son 16 (uno para cada posición en la rejilla 4x4), el estado (o posición actual) del agente puede calcularse como *fila actual x n_filas + columna actual*, donde tanto fila como columna empiezan en 0. Por ejemplo, la posicion inicial será el estado 0 (*estado = 0 x 4 + 0 = 0*). El estado final puede calcularse de la siguiente manera (*estado = 3 x 4 + 3 = 15*). O el bloque de hielo de la ultima fila seria (*estado = 3 x 4 + 0 = 12*) \n",
    "\n",
    "\n",
    "## Objetivo\n",
    "El objetivo del ejercicio es implementar diferentes estrategias de aprendizaje para entrenar al agente a maximizar su probabilidad de alcanzar la meta sin caer en los agujeros.\n",
    "\n",
    "Más en detalle, vamos a implementar diferentes politicas y algoritmos de aprendizaje por refuerzo.\n",
    "\n",
    "1. **Montecarlo**\n",
    "2. **Q-Learning**\n",
    "\n",
    "Además, utilizaremos para cada uno de los algoritmos diferentes politicas:\n",
    "\n",
    "1. **Greedy**\n",
    "2. **Epsilon-Greedy**\n",
    "3. **SOFTMAX**\n",
    "\n",
    "### Herramientas necesarias\n",
    "Este notebook utilizará:\n",
    "- **Python**: Para implementar el código.\n",
    "- **OpenAI Gym**: Para simular el entorno.\n",
    "- **Numpy**: Para cálculos numéricos.\n",
    "- **Matplotlib** (opcional): En caso de que quieras visualizar los resultados con más detalle.\n",
    "\n",
    "Para simplificar la configuración, y evitar problemas de versiones y configuraciones, tienes en el PDF adjunto de la práctica los pasos para instalar las librerias necesarias. \n",
    "\n",
    "Ahora si, con todo listo y sabiendo que tenemos que implementar, ¡comencemos a explorar Frozen Lake!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a286a5",
   "metadata": {},
   "source": [
    "Lo primero es importar, las librerias que vamos a utilizar. El entorno gym ya importa algunos paquetes cuando lo invocamos (como pygame) que es lo que nos permite visualizar el agente y el entorno. En este sentido, será suficiente con que importemos las librerias de Gymnasium y Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6968dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from gymnasium import RewardWrapper\n",
    "\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85687c",
   "metadata": {},
   "source": [
    "# Creación del entorno en Gym\n",
    "Ahora vamos a crear el entorno haciendo uso de la función **gym.make()** \n",
    "\n",
    "[Documentación de frozen lake](https://gymnasium.farama.org/environments/toy_text/frozen_lake/)\n",
    "\n",
    "- En el primer argumento del método (**id del juego**) le indicaremos el entorno que vamos a cargar, en este caso sera *FrozenLake-v1*. Si quisiesemos probar en otros entornos (aunque no es objetivo de la práctica), cambiariamos la versión o el nombre en este parámetro.\n",
    "\n",
    "- El segundo argumento **desc**, no lo vamos a utilizar (por simplicidad), pero basicamente nos permitiría definir nuestro propio entorno de obstaculos y bloques de hielo en lugar del entorno por defecto que vamos a utilizar.\n",
    "\n",
    "- Otro parametro importante es **map_name**, y depende del entorno. En el caso del juego *FrozenLake*, este puede obtener los valore \"4x4\" o \"8x8\". En nuestro caso, elegiremos el entorno 4x4, para facilitar la convergencia de los algoritmos.\n",
    "\n",
    "- **is_slippery** es un parámetro especifico del juego FrozenLake. Si el valor de este parámetro fuese True, lo que haría es aplicar un factor de \"resbalamiento\" o probabilidad de resbalar, que con una probabilidad 1/3 repetiria la acción anterior (simulando que el agente resbala y mantiene la dirección). Tal y como indicabamos previamente, no vamos a incluir este factor de aleatoriedad y pondremos el valor a False. Se usa en conjunción con el parámetro **success_rate** para indicar la probabilidad de resbalar en un bloque de hielo.\n",
    "\n",
    "- **reward_schedule** es el parámetro que permite modificar las recompensas obtenidas por el entorno. Como podras ver en la documentación, por defecto recibe (1, 0, 0), que son las recompensas que recibe el agente cuando alcanza la emta, alcanza un agujero, o alcanza un bloque de hielo respectivamente.\n",
    "\n",
    "- El último parámetro, que no aparece en la documentación es **render_mode**. Aunque se podria visualizar mediante una matriz que indique el estado (realmente se representa así), vamos a utilizar el modo \"human\" el cual usa pygame, y nos permitira ver el comportamiento del agente por pantalla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ff256cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea el entorno FrozenLake indicandole los parámetros. Para empezar, que el parámetro is_slippery = False.\n",
    "env = gym.make('FrozenLake-v1',\n",
    "               desc=None,\n",
    "               map_name=\"4x4\",\n",
    "               is_slippery=False,\n",
    "               reward_schedule=(1, 0, 0),\n",
    "               render_mode=\"human\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc2da10",
   "metadata": {},
   "source": [
    "# Exploración del entorno\n",
    "\n",
    "Una vez creado el entorno (env), gym nos provee de algunas funciones para explorar el entorno creado. En concreto, podemos invocar los métodos *env.obervation_space* y *env.action_space*. Ambos, permiten invocar el \"método\" n, que nos indica el tamaño del espacio de accion o de observación y el metodo \"sample()\" que seleccionaria de manera aleatoria un elemento del espacio (ya sea de accion o de observación). Visualiza por pantalla (con un print) el tamaño y una muestra aleatoria de cada uno de los espacios (de acciones y de observación). Como puedes comprobar (si ejecutas varias veces), el tamaño o es espacio no cambia, pero si la muestra elegida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c9dabec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espacio de observación\n",
      "\n",
      "Tamaño del espacio de observación: 16\n",
      "Estado del espacio de observación: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Espacio de observación\\n\")\n",
    "print(\"Tamaño del espacio de observación:\", env.observation_space.n)\n",
    "print(\"Estado del espacio de observación:\", env.observation_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e052d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espacio de acciones\n",
      "Tamaño del espacio de acciones: 4\n",
      "Estado del espacio de observación: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Espacio de acciones\")\n",
    "print(\"Tamaño del espacio de acciones:\", env.action_space.n)\n",
    "print(\"Estado del espacio de observación:\", env.action_space.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb508efe",
   "metadata": {},
   "source": [
    "# Ejecución simple del entorno FrozenLake\n",
    "\n",
    "Antes de empezar a programar políticas y algoritmos, vamos a comprobar que todo nos funciona correctamente. Para ello, vamos a ejecutar el entorno realizando movimientos aleatorios. Además, puedes programar tambien tu propio episodio donde el agente realice las acciones predeterminadas que determine.\n",
    "\n",
    "En el siguiente [Enlace](https://gymnasium.farama.org/api/env/) puedes ver los métodos más importantes para interactuar con el entorno. A modo de resumen, el **método reset** nos permite reiniciar el entorno entre diferentes episodios(ya que tras un episodio queremos volver a comenzar en la posición inicial). El **método render**, ya lo utilizamos al principio, pero nos permite visualizar lo que el agente hace (en este caso sera human ya que lo definimos previamente) aunque más adelante usaremos otros modos. Y por último, el método más importante es el método **step** ya que es el método que nos va a permitir la transicción de estado (dada una acción).\n",
    "\n",
    "Los pseudopasos a grandes rasgos (aunque te ayudo con los comentarios en la siguiente celda) son:\n",
    "\n",
    "1. Define el número de episodios\n",
    "2. Para cada episodio debemos de realizar una serie de pasos:\n",
    "   - Reinicia el entorno mediante el método reset.\n",
    "   - Mientras no hayamos alcanzado un estado terminal (esto se produce cuando alcanza la meta, o cae en un bloque de hielo)... \n",
    "        - Renderiza\n",
    "        - Elige una acción (en este caso elegiremos una acción aleatoria o predeterminada). Para el caso de la acción aleatoria, es preferible definir un método que realice dicha acción. En un futuro cambiaremos la politica ;) \n",
    "        - Ejecuta un step (ten en cuenta las variables que devuelve para que te funcione ;) )\n",
    "3. Recuerda cerrar el entorno mediante el **método env.close()** tras finalizar TODOS los episodios\n",
    "\n",
    "Tras implementar estos pasos correctamente, veras el tablero y como el agente interactua con el entorno.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f561411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/mani/lib/python3.11/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 3\n",
      "0 4 1\n",
      "0 0 3\n",
      "0 4 1\n",
      "0 8 1\n",
      "0 12 1\n",
      "1 0 3\n",
      "1 0 3\n",
      "1 1 2\n",
      "1 5 1\n"
     ]
    }
   ],
   "source": [
    "# Variables para almacenar la información de cada episodio\n",
    "\n",
    "\n",
    "#Define el número de episodios (2 es un buen número para empezar)\n",
    "episodes = 2\n",
    "for episode in range(episodes):\n",
    "    # Reiniciar el entorno\n",
    "    act, _ =env.reset()\n",
    "\n",
    "    # Simular un episodio hasta que llege.\n",
    "    terminated = False\n",
    "    while not (terminated):\n",
    "\n",
    "        # Elegir una acción aleatoria\n",
    "        act = env.action_space.sample()\n",
    "        \n",
    "        #Renderización del entorno para visualizar lo que el agente hace\n",
    "        env.render()\n",
    "\n",
    "        #Ejecutamos un step\n",
    "        observation,reward,terminated,truncated,_ = env.step(act)\n",
    "        \n",
    "        # Actualizar el estado\n",
    "        print(episode,observation,act)\n",
    "        \n",
    "#Cerramos el entorno\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a15aea2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set the learning rate [MIN: 0.3, MAX: 0.9, TYPE: float]: 0\n",
      "Set the discount reward [MIN: 0.8, MAX: 0.95, TYPE: float]: 0\n",
      "Set algorithm to train (Epsilon-greedy: 0 // Softmax: 1) [MIN: 0, MAX: 1, TYPE: int]: 0\n",
      "Set algorithm to train (Q-learning: 1 // SARSA: 2) [MIN: 1, MAX: 2, TYPE: int]: 0\n",
      "Set environment to use (FrozenLake-v1_4x4_noslip: 0 // LunarLander-v3: 1) [MIN: 0, MAX: 1, TYPE: int]: 0\n",
      "Set a starting epsilon [MIN: 0.1, MAX: 0.999, TYPE: float]: 0\n",
      "Set a minimum epsilon [MIN: 0.01, MAX: 0.001, TYPE: float]: 0\n",
      "Set a decay epsilon [MIN: 0.9, MAX: 0.999, TYPE: float]: 0\n",
      "Set max episodes to [MIN: 20, MAX: 1000, TYPE: int]: 0\n",
      "Set a window size (used to calculate mean of accumulated rewards) [MIN: 10, MAX: 200, TYPE: int]: 0\n"
     ]
    }
   ],
   "source": [
    "# Bounds to ask for parameters\n",
    "ALPHA_BOUND = [0.3,0.9,1]\n",
    "GAMMA_BOUND = [0.8,0.95,1]\n",
    "\n",
    "POLICY_BOUND = [0,1,0]\n",
    "ALGORITHM_BOUND = [1,2,0]\n",
    "ENVIRONMENT_BOUND = [0,1,0]\n",
    "\n",
    "VPOLICY_BOUND = [0.1,0.999,1]\n",
    "MINVPOLICY_BOUND = [0.01,0.001,1]\n",
    "DECAYVPOLICY_BOUND = [0.9,0.999,1]\n",
    "\n",
    "EPISODESENV0_BOUND = [20,1000,0]\n",
    "EPISODESENV1_BOUND = [500,5000,0]\n",
    "\n",
    "WINDOW_BOUND = [10,200,0]\n",
    "\n",
    "def inputBoundedParameter(text,bound):\n",
    "    datatype = \"int\"\n",
    "    if bound[2] > 0:\n",
    "        datatype = \"float\"\n",
    "\n",
    "    value = input(text+f\" [MIN: {bound[0]}, MAX: {bound[1]}, TYPE: {datatype}]: \")\n",
    "    if bound[2] < 1:\n",
    "        return min(max(int(value),bound[0]),bound[1])\n",
    "    return min(max(float(value),bound[0]),bound[1])\n",
    "\n",
    "    \n",
    "\n",
    "# Intrinsic RL parameters\n",
    "alpha = inputBoundedParameter(\"Set the learning rate\",ALPHA_BOUND)    # Learning rate parameter\n",
    "gamma = inputBoundedParameter(\"Set the discount reward\",GAMMA_BOUND)  # Discount parameter\n",
    "\n",
    "environment = inputBoundedParameter(\"Set environment to use (FrozenLake-v1_4x4_noslip: 0 // LunarLander-v3: 1)\",ENVIRONMENT_BOUND)\n",
    "algorithm = inputBoundedParameter(\"Set algorithm to train (Q-learning: 1 // SARSA: 2)\",ALGORITHM_BOUND)\n",
    "policy = inputBoundedParameter(\"Set policy to use (Epsilon-greedy: 0 // Softmax: 1)\",POLICY_BOUND)\n",
    "\n",
    "if algorithm < 2:\n",
    "    s1 = \"starting\"\n",
    "else:\n",
    "    s1 = \"permanent\"\n",
    "\n",
    "if policy < 1:\n",
    "    s2 = \"epsilon\"\n",
    "else:\n",
    "    s2 = \"temperature\"\n",
    "\n",
    "\n",
    "v_policy = inputBoundedParameter(f\"Set a {s1} {s2}\",VPOLICY_BOUND)\n",
    "\n",
    "if algorithm < 2:\n",
    "    min_v_policy = inputBoundedParameter(f\"Set a minimum {s2}\",MINVPOLICY_BOUND)\n",
    "    decay_v_policy = inputBoundedParameter(f\"Set a decay {s2}\",DECAYVPOLICY_BOUND)\n",
    "\n",
    "# Total episodes of the training\n",
    "if environment < 1:\n",
    "    envname = \"FrozenLake-v1\"\n",
    "    episodes = inputBoundedParameter(\"Set max episodes\",EPISODESENV0_BOUND)\n",
    "else:\n",
    "    envname = \"LunarLander-v3\"\n",
    "    episodes = inputBoundedParameter(\"Set max episodes\",EPISODESENV1_BOUND)\n",
    "    \n",
    "window = inputBoundedParameter(\"Set a window size (used to calculate mean of accumulated rewards)\",WINDOW_BOUND) \n",
    "\n",
    "\n",
    "if policy < 1:\n",
    "    epsilon = v_policy\n",
    "    if algorithm < 2:\n",
    "        min_epsilon = min_v_policy\n",
    "        decay_epsilon = decay_v_policy\n",
    "else:\n",
    "    temperature = v_policy\n",
    "    if algorithm < 2:\n",
    "        min_temperature = min_v_policy\n",
    "        decay_temperature = decay_v_policy\n",
    "\n",
    "# Action policies\n",
    "\n",
    "def epsilon_greedy(state,epsilon):\n",
    "    if random.uniform(0,1) < epsilon:\n",
    "        return env.action_space.sample()\n",
    "    return np.argmax(Q[state])\n",
    "\n",
    "def softmax(state, temperature):\n",
    "    q_values = Q[state]\n",
    "    # Evitar overflow: restar el max\n",
    "    z = (q_values - np.max(q_values)) / max(temperature, 1e-6)\n",
    "    probs = np.exp(z)\n",
    "    probs /= np.sum(probs)\n",
    "    return int(np.random.choice(len(q_values), p=probs))\n",
    "\n",
    "def select_action(state,policy,parameter_policy):\n",
    "    if policy < 1:\n",
    "        return epsilon_greedy(state,parameter_policy)\n",
    "    return softmax(state,parameter_policy)\n",
    "    \n",
    "\n",
    "\n",
    "# =========== LUNAR-LANDER ONLY ===========\n",
    "\n",
    "bins = 12 # Amount of subdivisions space is divided\n",
    "\n",
    "# State discretization values -> x,y,vx,vy,angle,w,contactleg1,contactleg2\n",
    "state_bins = [\n",
    "    np.linspace(-1.2, 1.2, bins),\n",
    "    np.linspace(-1.2, 1.2, bins),\n",
    "    np.linspace(-2.0, 2.0, bins),\n",
    "    np.linspace(-2.0, 2.0, bins),\n",
    "    np.linspace(-3.14, 3.14, bins),\n",
    "    np.linspace(-5.0, 5.0, bins),\n",
    "    np.array([0, 1]),\n",
    "    np.array([0, 1])\n",
    "]\n",
    "\n",
    "\n",
    "# State discretization function\n",
    "def discretize(state):\n",
    "    disc = []\n",
    "    for i in range(len(state)):\n",
    "        if i < 6:\n",
    "            disc.append(int(np.digitize(state[i], state_bins[i])))\n",
    "        else:\n",
    "            disc.append(int(state[i]))\n",
    "    return tuple(disc)\n",
    "\n",
    "target_mean_reward = 200  # Standard objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cea9dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo guardado como FrozenLake-v1_qtable.pkl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ================ Lunar-Lander ================\n",
    "\n",
    "# Storing variables\n",
    "\n",
    "# Action, reward and next state matrix [i][j] (i -> Episode // j -> Step on that episode)\n",
    "ev_act = []\n",
    "ev_reward = []\n",
    "ev_state = []\n",
    "\n",
    "# Epsilon and accumulated reward matrix (length = episodes)\n",
    "ev_epsilon = []\n",
    "acc_reward = []\n",
    "\n",
    "best_mean = -np.inf\n",
    "\n",
    "# Environment initialization\n",
    "if environment < 1:\n",
    "    env = gym.make(envname,desc=None,map_name=\"4x4\",is_slippery=False,reward_schedule=(10, -1, -1),render_mode=\"human\")\n",
    "else:\n",
    "    env = gym.make(envname,render_mode=None)\n",
    "\n",
    "# Q-table first initialization\n",
    "if environment < 1:\n",
    "    Q = (-1)*np.ones([env.observation_space.n, env.action_space.n])\n",
    "else:\n",
    "    Q = np.zeros([bins+1] * 6 + [2, 2] + [env.action_space.n])\n",
    "\n",
    "best_Q = None\n",
    "\n",
    "# Epsilon-greedy parameters\n",
    "epsilon = 0.999       # Starting (Q-learning only) epsilon value\n",
    "min_epsilon = 0.05    # Minimum epsilon value achievable\n",
    "decay_epsilon = 0.995 # Decay parameter for epsilon greedy (enacted each episode once goal is reached)\n",
    "\n",
    "# Softmax parameters\n",
    "temperature = 0.999         # Starting (Q-learning only) temperature value\n",
    "min_temperature = 0.1       # Minimum temperature value achievable\n",
    "decay_temperature = 0.995   # Decay parameter for softmax (enacted each episode once goal is reached)\n",
    "\n",
    "\n",
    "if environment < 1:\n",
    "    max_steps = 20  # Maximum steps allowed before terminating episode no matter what\n",
    "\n",
    "mean_recent = -200\n",
    "\n",
    "# Flag and episode number when objective is reached for first time\n",
    "objective_reached = False\n",
    "ep_ob_reached = -1\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Training phase\n",
    "for episode in range(1,episodes+1):\n",
    "    # Environment reset\n",
    "    state, _ =env.reset()\n",
    "\n",
    "    # Prepare store data for this episode (epsilon only used for Q-learning + ep_greedy)\n",
    "    if environment < 1:\n",
    "        ev_state.append([])\n",
    "        ev_act.append([])\n",
    "        ev_reward.append([])\n",
    "        steps = 0\n",
    "    else:\n",
    "        state = discretize(state)\n",
    "\n",
    "    ev_epsilon.append(epsilon)\n",
    "    acc_reward.append(0.0)\n",
    "\n",
    "    # Set termination flags\n",
    "    terminated = False\n",
    "    truncated = False  # NOT USED\n",
    "    \n",
    "    if algorithm >= 2:\n",
    "        #act = epsilon_greedy(state,epsilon)\n",
    "        act = select_action(state,policy,v_policy)\n",
    "    \n",
    "    \n",
    "    # Episode simulation\n",
    "    while not (terminated):\n",
    "\n",
    "\n",
    "        # Action calculation (not SARSA)\n",
    "        if algorithm < 2:\n",
    "            # act = epsilon_greedy(state,epsilon)\n",
    "            act = select_action(state,policy,v_policy)\n",
    "\n",
    "\n",
    "        # Step execution\n",
    "        next_state,reward,terminated,truncated,_ = env.step(act)\n",
    "        \n",
    "        if environment > 1:\n",
    "            next_state = discretize(next_state)\n",
    "        \n",
    "\n",
    "        # Next best action calculation (Motecarlo and Q-learning only)\n",
    "        if algorithm < 2:\n",
    "            next_act = np.argmax(Q[next_state])\n",
    "        # Next action calculation (SARSA)\n",
    "        else:\n",
    "            # next_act = epsilon_greedy(state)\n",
    "            next_act = select_action(state,policy,v_policy)\n",
    "\n",
    "\n",
    "        # Q-table and state update\n",
    "        Q[state][act] += alpha * (reward + gamma * Q[next_state][next_act] - Q[state][act])\n",
    "        state = next_state\n",
    "        \n",
    "        # Save all gathered step info\n",
    "        if environment < 1:\n",
    "            ev_act[episode-1].append(act)\n",
    "            ev_reward[episode-1].append(reward)\n",
    "            ev_state[episode-1].append(state)\n",
    "        acc_reward[episode-1] += reward\n",
    "\n",
    "\n",
    "        # Start to erode epsilon value once target is reached for first time (Q-learning+ep_greedy only)\n",
    "        if mean_recent >= -150.0 and not objective_reached:\n",
    "            objective_reached = True\n",
    "            ep_ob_reached = episode\n",
    "        \n",
    "        # End condition, so each episode doesn't take absurdly long\n",
    "        if environment < 1:\n",
    "            if steps >= max_steps:\n",
    "                terminated = True\n",
    "            steps += 1\n",
    "\n",
    "    if objective_reached and algorithm < 2:\n",
    "        epsilon = max(min_epsilon,epsilon*decay_epsilon)\n",
    "        temperature = max(min_temperature,temperature*decay_temperature)\n",
    "        \n",
    "    # Estadísticas y parada temprana por media móvil\n",
    "    if len(acc_reward) >= window:\n",
    "        mean_recent = np.mean(acc_reward[-window:])\n",
    "        if mean_recent > best_mean:\n",
    "            best_mean = mean_recent\n",
    "            best_Q = Q.copy()\n",
    "        if mean_recent >= target_mean_reward:\n",
    "            print(f\"Parada temprana en episodio {episode}: media {mean_recent:.2f}\")\n",
    "            break\n",
    "\n",
    "    if episode % window == 0:\n",
    "        mean_recent = np.mean(acc_reward[-min(len(acc_reward), window):])\n",
    "        elapsed = time.time() - start_time\n",
    "        print(\n",
    "            f\"Episode {episode} | Reward {acc_reward[episode-1]:.1f} | Mean({min(len(acc_reward), window)}) \"\n",
    "            f\"{mean_recent:.1f} | eps {epsilon:.3f} | temp {temperature:.3f} | alpha {alpha:.3f} | t {elapsed/60:.1f}m\"\n",
    "        )\n",
    "\n",
    "# Guardar el mejor modelo disponible\n",
    "to_save = best_Q if best_Q is not None else Q\n",
    "with open(f\"{envname}_qtable.pkl\", \"wb\") as f:\n",
    "    pickle.dump(to_save, f)\n",
    "print(f\"\\nModelo guardado como {envname}_qtable.pkl\\n\")\n",
    "\n",
    "env.close() # Close environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6df59702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training phase\n",
    "for episode in range(episodes):\n",
    "    # Environment reset\n",
    "    act, _ =env.reset()\n",
    "    state = 0\n",
    "    steps = 0\n",
    "    \n",
    "    # Set termination flags\n",
    "    terminated = False\n",
    "    truncated = False  # NOT USED\n",
    "\n",
    "    # First action (only used with SARSA)\n",
    "    act = epsilon_greedy(state)\n",
    "    \n",
    "    # Episode simulation\n",
    "    while not (terminated):\n",
    "\n",
    "        # Step execution\n",
    "        next_state,reward,terminated,truncated,_ = env.step(act)\n",
    "\n",
    "        # Next action calculation (SARSA)\n",
    "        next_act = epsilon_greedy(state)\n",
    "        \n",
    "        # Q-table and state update (also action for SARSA)\n",
    "        Q[state][act] += alpha * (reward + gamma * Q[next_state][next_act] - Q[state][act])\n",
    "        state = next_state\n",
    "        act = next_act\n",
    "        \n",
    "        # Save all gathered step info\n",
    "        ev_act[episode].append(act)\n",
    "        ev_reward[episode].append(reward)\n",
    "        ev_state[episode].append(state)\n",
    "        acc_reward[episode] += reward\n",
    "\n",
    "\n",
    "        # Start to erode epsilon value once target is reached for first time (Q-learning+ep_greedy only)\n",
    "        if reward > 0.0 and not objective_reached:\n",
    "            objective_reached = True\n",
    "            ep_ob_reached = episode\n",
    "        \n",
    "        # End condition, so each episode doesn't take absurdly long\n",
    "        if steps >= max_steps:\n",
    "            terminated = True\n",
    "        steps += 1\n",
    "\n",
    "env.close() # Close environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6345c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================ Q-LEARNING ALGORITHM (EPSILON_GREEDY) ================\n",
    "\n",
    "# Q-table first initialization\n",
    "Q = (-1)*np.ones([env.observation_space.n, env.action_space.n])\n",
    "\n",
    "# Storing variables\n",
    "\n",
    "# Action, reward and next state matrix [i][j] (i -> Episode // j -> Step on that episode)\n",
    "ev_act = []\n",
    "ev_reward = []\n",
    "ev_state = []\n",
    "\n",
    "# Epsilon and accumulated reward matrix (length = episodes)\n",
    "ev_epsilon = []\n",
    "acc_reward = []\n",
    "\n",
    "# Environment initialization\n",
    "env = gym.make('FrozenLake-v1',desc=None,map_name=\"4x4\",is_slippery=False,reward_schedule=(10, -1, -1))\n",
    "\n",
    "\n",
    "# Epsilon-greedy parameters\n",
    "epsilon = 0.999      # Starting (Q-learning only) epsilon value\n",
    "min_epsilon = 0.05   # Minimum epsilon value achievable\n",
    "decay_epsilon = 0.05 # Decay parameter for epsilon greedy (enacted each episode once goal is reached)\n",
    "\n",
    "# Softmax parameters\n",
    "temperature_start = 0.999   # Starting (Q-learning only) temperature value\n",
    "temperature_min = 0.1       # Minimum temperature value achievable\n",
    "temperature_decay = 0.995   # Decay parameter for softmax (enacted each episode once goal is reached)\n",
    "\n",
    "\n",
    "episodes = 100  # Total episodes of the training\n",
    "max_steps = 20  # Maximum steps allowed before terminating episode no matter what\n",
    "\n",
    "# Flag and episode number when objective is reached for first time\n",
    "objective_reached = False\n",
    "ep_ob_reached = -1\n",
    "\n",
    "# Training phase\n",
    "for episode in range(episodes):\n",
    "    # Environment reset\n",
    "    act, _ =env.reset()\n",
    "    state = 0\n",
    "    steps = 0\n",
    "\n",
    "    # Prepare store data for this episode (epsilon only used for Q-learning + ep_greedy)\n",
    "    ev_state.append([])\n",
    "    ev_act.append([])\n",
    "    ev_reward.append([])\n",
    "    ev_epsilon.append(epsilon)\n",
    "    acc_reward.append(0.0)\n",
    "\n",
    "    # Set termination flags\n",
    "    terminated = False\n",
    "    truncated = False  # NOT USED\n",
    "    \n",
    "    # Episode simulation\n",
    "    while not (terminated):\n",
    "\n",
    "\n",
    "        # Action calculation (not SARSA)\n",
    "        act = epsilon_greedy(state,epsilon)\n",
    "\n",
    "\n",
    "        # Step execution\n",
    "        next_state,reward,terminated,truncated,_ = env.step(act)\n",
    "        \n",
    "\n",
    "        # Next best action calculation (Motecarlo and Q-learning only)\n",
    "        best = np.argmax(Q[next_state])\n",
    "\n",
    "        # Q-table and state update\n",
    "        Q[state][act] += alpha * (reward + gamma * Q[next_state][best] - Q[state][act])\n",
    "        state = next_state\n",
    "        \n",
    "        # Save all gathered step info\n",
    "        ev_act[episode].append(act)\n",
    "        ev_reward[episode].append(reward)\n",
    "        ev_state[episode].append(state)\n",
    "        acc_reward[episode] += reward\n",
    "\n",
    "\n",
    "        # Start to erode epsilon value once target is reached for first time (Q-learning+ep_greedy only)\n",
    "        if reward > 0.0 and not objective_reached:\n",
    "            objective_reached = True\n",
    "            ep_ob_reached = episode\n",
    "        \n",
    "        # End condition, so each episode doesn't take absurdly long\n",
    "        if steps >= max_steps:\n",
    "            terminated = True\n",
    "        steps += 1\n",
    "\n",
    "    if objective_reached:\n",
    "        epsilon = max(min_epsilon,epsilon*decay_epsilon)\n",
    "\n",
    "env.close() # Close environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1942bf3f",
   "metadata": {},
   "source": [
    "# Visualización de resultados\n",
    "\n",
    "Una vez te has familiarizado con el entorno, el siguiente paso es analizar y visualizar el comportamiento del agente durante un episodio, así como durante todo el entrenamiento. Para ello, deberás crear nuevas variables que permitan guardar la información. \n",
    "\n",
    "Ten en cuenta que entre los aspectos que vas a querer visualizar son: \n",
    "\n",
    "- Trayectoria completa del episodio, mostrando las secuencias de estados y acciones.\n",
    "\n",
    "- Recompensa inmediata obtenida en cada paso.\n",
    "\n",
    "- Recompensa acumulada a lo largo del episodio.\n",
    "\n",
    "- Recompensa media por paso o por episodio.\n",
    "\n",
    "- Detección de estados terminales y las condiciones que los producen.\n",
    "\n",
    "- Evolución temporal de las observaciones y variables relevantes del entorno.\n",
    "\n",
    "Es posible que quieras crear alguna funcion predeterminada (política determinista) que te permita simular ciertas situaciones que quieres poder visualizar, como por ejemplo la detección de estados terminales y las condiciones que los producen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7882f83-a897-49f1-8daa-521225111fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================\n",
      "Episode: 0 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 0  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -2.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 1 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 0  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 0  //  Reward: -1  // Next_state: 0\n",
      "Step:02  //  Action: 0  //  Reward: -1  // Next_state: 0\n",
      "Step:03  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:04  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:05  //  Action: 0  //  Reward: -1  // Next_state: 8\n",
      "Step:06  //  Action: 1  //  Reward: -1  // Next_state: 8\n",
      "Step:07  //  Action: 1  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -8.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 2 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 0  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 0  //  Reward: -1  // Next_state: 4\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 4\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 3 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 3  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 3  //  Reward: -1  // Next_state: 0\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:03  //  Action: 3  //  Reward: -1  // Next_state: 1\n",
      "Step:04  //  Action: 0  //  Reward: -1  // Next_state: 1\n",
      "Step:05  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:06  //  Action: 0  //  Reward: -1  // Next_state: 1\n",
      "Step:07  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:08  //  Action: 0  //  Reward: -1  // Next_state: 1\n",
      "Step:09  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:10  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:11  //  Action: 1  //  Reward: -1  // Next_state: 8\n",
      "Step:12  //  Action: 0  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -13.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 4 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 3  //  Reward: -1  // Next_state: 4\n",
      "Step:02  //  Action: 3  //  Reward: -1  // Next_state: 0\n",
      "Step:03  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:04  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:05  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:06  //  Action: 2  //  Reward: -1  // Next_state: 9\n",
      "Step:07  //  Action: 0  //  Reward: -1  // Next_state: 10\n",
      "Step:08  //  Action: 3  //  Reward: -1  // Next_state: 9\n",
      "Step:09  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -10.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 5 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 0  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:04  //  Action: 0  //  Reward: -1  // Next_state: 9\n",
      "Step:05  //  Action: 0  //  Reward: -1  // Next_state: 8\n",
      "Step:06  //  Action: 3  //  Reward: -1  // Next_state: 8\n",
      "Step:07  //  Action: 3  //  Reward: -1  // Next_state: 4\n",
      "Step:08  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:09  //  Action: 3  //  Reward: -1  // Next_state: 4\n",
      "Step:10  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:11  //  Action: 3  //  Reward: -1  // Next_state: 1\n",
      "Step:12  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:13  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:14  //  Action: 2  //  Reward: -1  // Next_state: 6\n",
      "Step:15  //  Action: 1  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -16.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 6 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:02  //  Action: 0  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -3.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 7 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:02  //  Action: 0  //  Reward: -1  // Next_state: 2\n",
      "Step:03  //  Action: 0  //  Reward: -1  // Next_state: 1\n",
      "Step:04  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:05  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:06  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:07  //  Action: 3  //  Reward: -1  // Next_state: 9\n",
      "Step:08  //  Action: 0  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -9.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 8 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -2.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 9 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 2\n",
      "Step:02  //  Action: 0  //  Reward: -1  // Next_state: 3\n",
      "Step:03  //  Action: 0  //  Reward: -1  // Next_state: 2\n",
      "Step:04  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:05  //  Action: 3  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -6.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 10 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 3  //  Reward: -1  // Next_state: 2\n",
      "Step:02  //  Action: 3  //  Reward: -1  // Next_state: 2\n",
      "Step:03  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:04  //  Action: 1  //  Reward: -1  // Next_state: 6\n",
      "Step:05  //  Action: 0  //  Reward: -1  // Next_state: 10\n",
      "Step:06  //  Action: 3  //  Reward: -1  // Next_state: 9\n",
      "Step:07  //  Action: 3  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -8.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 11 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 3  //  Reward: -1  // Next_state: 2\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 2\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 3\n",
      "Step:04  //  Action: 1  //  Reward: -1  // Next_state: 3\n",
      "Step:05  //  Action: 3  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -6.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 12 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 3  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:03  //  Action: 3  //  Reward: -1  // Next_state: 2\n",
      "Step:04  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:05  //  Action: 2  //  Reward: -1  // Next_state: 6\n",
      "Step:06  //  Action: 3  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -7.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 13 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -2.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 14 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:02  //  Action: 0  //  Reward: -1  // Next_state: 8\n",
      "Step:03  //  Action: 3  //  Reward: -1  // Next_state: 8\n",
      "Step:04  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:05  //  Action: 0  //  Reward: -1  // Next_state: 8\n",
      "Step:06  //  Action: 1  //  Reward: -1  // Next_state: 8\n",
      "Step:07  //  Action: 1  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -8.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 15 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 0  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:03  //  Action: 1  //  Reward: -1  // Next_state: 9\n",
      "Step:04  //  Action: 1  //  Reward: -1  // Next_state: 13\n",
      "Step:05  //  Action: 0  //  Reward: -1  // Next_state: 13\n",
      "Step:06  //  Action: 0  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -7.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 16 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 0  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:03  //  Action: 1  //  Reward: -1  // Next_state: 9\n",
      "Step:04  //  Action: 1  //  Reward: -1  // Next_state: 13\n",
      "Step:05  //  Action: 1  //  Reward: -1  // Next_state: 13\n",
      "Step:06  //  Action: 2  //  Reward: -1  // Next_state: 13\n",
      "Step:07  //  Action: 3  //  Reward: -1  // Next_state: 14\n",
      "Step:08  //  Action: 0  //  Reward: -1  // Next_state: 10\n",
      "Step:09  //  Action: 0  //  Reward: -1  // Next_state: 9\n",
      "Step:10  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:11  //  Action: 1  //  Reward: -1  // Next_state: 9\n",
      "Step:12  //  Action: 2  //  Reward: -1  // Next_state: 13\n",
      "Step:13  //  Action: 3  //  Reward: -1  // Next_state: 14\n",
      "Step:14  //  Action: 1  //  Reward: -1  // Next_state: 10\n",
      "Step:15  //  Action: 0  //  Reward: -1  // Next_state: 14\n",
      "Step:16  //  Action: 0  //  Reward: -1  // Next_state: 13\n",
      "Step:17  //  Action: 3  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -18.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 17 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 3  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 0  //  Reward: -1  // Next_state: 1\n",
      "Step:02  //  Action: 3  //  Reward: -1  // Next_state: 0\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:04  //  Action: 3  //  Reward: -1  // Next_state: 1\n",
      "Step:05  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:06  //  Action: 2  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -7.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 18 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 3  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:02  //  Action: 3  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -3.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 19 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 3  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:02  //  Action: 0  //  Reward: -1  // Next_state: 1\n",
      "Step:03  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:04  //  Action: 2  //  Reward: -1  // Next_state: 4\n",
      "Step:05  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -6.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 20 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -3.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 21 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 8\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 22 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 0  //  Reward: -1  // Next_state: 1\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:04  //  Action: 3  //  Reward: -1  // Next_state: 2\n",
      "Step:05  //  Action: 2  //  Reward: -1  // Next_state: 2\n",
      "Step:06  //  Action: 2  //  Reward: -1  // Next_state: 3\n",
      "Step:07  //  Action: 3  //  Reward: -1  // Next_state: 3\n",
      "Step:08  //  Action: 3  //  Reward: -1  // Next_state: 3\n",
      "Step:09  //  Action: 3  //  Reward: -1  // Next_state: 3\n",
      "Step:10  //  Action: 0  //  Reward: -1  // Next_state: 3\n",
      "Step:11  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:12  //  Action: 1  //  Reward: -1  // Next_state: 6\n",
      "Step:13  //  Action: 2  //  Reward: -1  // Next_state: 10\n",
      "Step:14  //  Action: 0  //  Reward: -1  // Next_state: 11\n",
      "\n",
      "Accumulated_reward: -15.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 11\n",
      "\n",
      "============================\n",
      "Episode: 23 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 0  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 4\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -3.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 24 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 0  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:04  //  Action: 1  //  Reward: -1  // Next_state: 9\n",
      "Step:05  //  Action: 3  //  Reward: -1  // Next_state: 13\n",
      "Step:06  //  Action: 3  //  Reward: -1  // Next_state: 9\n",
      "Step:07  //  Action: 2  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -8.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 25 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 3  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -3.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 26 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 9\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 13\n",
      "Step:04  //  Action: 3  //  Reward: -1  // Next_state: 14\n",
      "Step:05  //  Action: 1  //  Reward: -1  // Next_state: 10\n",
      "Step:06  //  Action: 3  //  Reward: -1  // Next_state: 14\n",
      "Step:07  //  Action: 1  //  Reward: -1  // Next_state: 10\n",
      "Step:08  //  Action: 0  //  Reward: -1  // Next_state: 14\n",
      "Step:09  //  Action: 1  //  Reward: -1  // Next_state: 13\n",
      "Step:10  //  Action: 0  //  Reward: -1  // Next_state: 13\n",
      "Step:11  //  Action: 3  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -12.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 27 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 0  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 4\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 28 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 9\n",
      "Step:03  //  Action: 3  //  Reward: -1  // Next_state: 13\n",
      "Step:04  //  Action: 3  //  Reward: -1  // Next_state: 9\n",
      "Step:05  //  Action: 3  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -6.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 29 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -2.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 30 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 3  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 4\n",
      "Step:03  //  Action: 3  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 31 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 6\n",
      "Step:03  //  Action: 1  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 32 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -3.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 33 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 6\n",
      "Step:03  //  Action: 3  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 34 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 0  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 8\n",
      "Step:03  //  Action: 0  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 35 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 3  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -2.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 36 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 4\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -3.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 37 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 8\n",
      "Step:03  //  Action: 3  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 38 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -2.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 39 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 0  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 8\n",
      "Step:03  //  Action: 3  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 40 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 0  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:03  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:04  //  Action: 1  //  Reward: -1  // Next_state: 6\n",
      "Step:05  //  Action: 0  //  Reward: -1  // Next_state: 10\n",
      "Step:06  //  Action: 3  //  Reward: -1  // Next_state: 9\n",
      "Step:07  //  Action: 2  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -8.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 41 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 3  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -3.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 42 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 0  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:03  //  Action: 0  //  Reward: -1  // Next_state: 2\n",
      "Step:04  //  Action: 3  //  Reward: -1  // Next_state: 1\n",
      "Step:05  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:06  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -7.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 43 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 9\n",
      "Step:03  //  Action: 1  //  Reward: -1  // Next_state: 13\n",
      "Step:04  //  Action: 0  //  Reward: -1  // Next_state: 13\n",
      "Step:05  //  Action: 0  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -6.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 44 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 6\n",
      "Step:03  //  Action: 1  //  Reward: -1  // Next_state: 10\n",
      "Step:04  //  Action: 3  //  Reward: -1  // Next_state: 14\n",
      "Step:05  //  Action: 1  //  Reward: -1  // Next_state: 10\n",
      "Step:06  //  Action: 1  //  Reward: -1  // Next_state: 14\n",
      "Step:07  //  Action: 3  //  Reward: -1  // Next_state: 14\n",
      "Step:08  //  Action: 2  //  Reward: -1  // Next_state: 10\n",
      "Step:09  //  Action: 3  //  Reward: -1  // Next_state: 11\n",
      "\n",
      "Accumulated_reward: -10.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 11\n",
      "\n",
      "============================\n",
      "Episode: 45 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 3  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 3  //  Reward: -1  // Next_state: 1\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:03  //  Action: 3  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 46 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -2.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 47 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 2\n",
      "Step:02  //  Action: 0  //  Reward: -1  // Next_state: 3\n",
      "Step:03  //  Action: 3  //  Reward: -1  // Next_state: 2\n",
      "Step:04  //  Action: 0  //  Reward: -1  // Next_state: 2\n",
      "Step:05  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:06  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:07  //  Action: 2  //  Reward: -1  // Next_state: 6\n",
      "Step:08  //  Action: 1  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -9.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 48 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 6\n",
      "Step:03  //  Action: 0  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 49 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 0  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 3  //  Reward: -1  // Next_state: 0\n",
      "Step:02  //  Action: 3  //  Reward: -1  // Next_state: 0\n",
      "Step:03  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:04  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:05  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:06  //  Action: 0  //  Reward: -1  // Next_state: 9\n",
      "Step:07  //  Action: 1  //  Reward: -1  // Next_state: 8\n",
      "Step:08  //  Action: 1  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -9.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 50 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:03  //  Action: 0  //  Reward: -1  // Next_state: 6\n",
      "Step:04  //  Action: 0  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -5.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 51 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 3  //  Reward: -1  // Next_state: 9\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 52 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 9\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 13\n",
      "Step:04  //  Action: 0  //  Reward: -1  // Next_state: 14\n",
      "Step:05  //  Action: 0  //  Reward: -1  // Next_state: 13\n",
      "Step:06  //  Action: 2  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -7.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 53 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 2\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 3\n",
      "Step:04  //  Action: 3  //  Reward: -1  // Next_state: 3\n",
      "Step:05  //  Action: 1  //  Reward: -1  // Next_state: 3\n",
      "Step:06  //  Action: 2  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -7.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 54 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 0  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -2.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 55 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 2\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 3\n",
      "Step:03  //  Action: 1  //  Reward: -1  // Next_state: 3\n",
      "Step:04  //  Action: 0  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -5.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 56 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 6\n",
      "Step:03  //  Action: 3  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 57 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -2.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 58 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:02  //  Action: 3  //  Reward: -1  // Next_state: 2\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 2\n",
      "Step:04  //  Action: 2  //  Reward: -1  // Next_state: 3\n",
      "Step:05  //  Action: 1  //  Reward: -1  // Next_state: 3\n",
      "Step:06  //  Action: 1  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -7.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 59 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 0  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 4\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 60 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 3  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -2.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 61 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -2.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 62 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 0  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 8\n",
      "Step:03  //  Action: 1  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 63 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 6\n",
      "Step:03  //  Action: 3  //  Reward: -1  // Next_state: 10\n",
      "Step:04  //  Action: 3  //  Reward: -1  // Next_state: 6\n",
      "Step:05  //  Action: 0  //  Reward: -1  // Next_state: 2\n",
      "Step:06  //  Action: 0  //  Reward: -1  // Next_state: 1\n",
      "Step:07  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:08  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:09  //  Action: 1  //  Reward: -1  // Next_state: 8\n",
      "Step:10  //  Action: 3  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -11.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 64 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -2.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 65 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -2.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 66 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 6\n",
      "Step:03  //  Action: 0  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 67 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:02  //  Action: 3  //  Reward: -1  // Next_state: 8\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 4\n",
      "Step:04  //  Action: 2  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -5.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 68 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 6\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 69 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -3.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 70 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 6\n",
      "Step:04  //  Action: 1  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -5.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 71 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 9\n",
      "Step:03  //  Action: 1  //  Reward: -1  // Next_state: 13\n",
      "Step:04  //  Action: 0  //  Reward: -1  // Next_state: 13\n",
      "Step:05  //  Action: 3  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -6.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 72 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -2.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 73 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 6\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 74 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 0  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:03  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 75 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 3  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 4\n",
      "Step:03  //  Action: 3  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 76 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 9\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 13\n",
      "Step:04  //  Action: 1  //  Reward: -1  // Next_state: 14\n",
      "Step:05  //  Action: 3  //  Reward: -1  // Next_state: 14\n",
      "Step:06  //  Action: 1  //  Reward: -1  // Next_state: 10\n",
      "Step:07  //  Action: 1  //  Reward: -1  // Next_state: 14\n",
      "Step:08  //  Action: 0  //  Reward: -1  // Next_state: 14\n",
      "Step:09  //  Action: 3  //  Reward: -1  // Next_state: 13\n",
      "Step:10  //  Action: 0  //  Reward: -1  // Next_state: 9\n",
      "Step:11  //  Action: 0  //  Reward: -1  // Next_state: 8\n",
      "Step:12  //  Action: 1  //  Reward: -1  // Next_state: 8\n",
      "Step:13  //  Action: 2  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -14.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 77 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -3.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 78 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 0  //  Reward: -1  // Next_state: 2\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:03  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:04  //  Action: 2  //  Reward: -1  // Next_state: 6\n",
      "Step:05  //  Action: 0  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -6.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 79 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 3  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 0  //  Reward: -1  // Next_state: 0\n",
      "Step:02  //  Action: 0  //  Reward: -1  // Next_state: 0\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:04  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:05  //  Action: 2  //  Reward: -1  // Next_state: 2\n",
      "Step:06  //  Action: 0  //  Reward: -1  // Next_state: 3\n",
      "Step:07  //  Action: 2  //  Reward: -1  // Next_state: 2\n",
      "Step:08  //  Action: 2  //  Reward: -1  // Next_state: 3\n",
      "Step:09  //  Action: 1  //  Reward: -1  // Next_state: 3\n",
      "Step:10  //  Action: 1  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -11.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 80 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 3  //  Reward: -1  // Next_state: 9\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 81 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 0  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 3  //  Reward: -1  // Next_state: 4\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:03  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:04  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -5.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 82 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 9\n",
      "Step:03  //  Action: 0  //  Reward: -1  // Next_state: 13\n",
      "Step:04  //  Action: 1  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -5.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 83 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 0  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:02  //  Action: 0  //  Reward: -1  // Next_state: 1\n",
      "Step:03  //  Action: 1  //  Reward: -1  // Next_state: 0\n",
      "Step:04  //  Action: 3  //  Reward: -1  // Next_state: 4\n",
      "Step:05  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:06  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:07  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:08  //  Action: 1  //  Reward: -1  // Next_state: 6\n",
      "Step:09  //  Action: 0  //  Reward: -1  // Next_state: 10\n",
      "Step:10  //  Action: 3  //  Reward: -1  // Next_state: 9\n",
      "Step:11  //  Action: 0  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -12.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 84 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 6\n",
      "Step:03  //  Action: 0  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 85 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 9\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 13\n",
      "Step:04  //  Action: 0  //  Reward: -1  // Next_state: 14\n",
      "Step:05  //  Action: 2  //  Reward: -1  // Next_state: 13\n",
      "Step:06  //  Action: 3  //  Reward: -1  // Next_state: 14\n",
      "Step:07  //  Action: 1  //  Reward: -1  // Next_state: 10\n",
      "Step:08  //  Action: 3  //  Reward: -1  // Next_state: 14\n",
      "Step:09  //  Action: 1  //  Reward: -1  // Next_state: 10\n",
      "Step:10  //  Action: 2  //  Reward: -1  // Next_state: 14\n",
      "Step:11  //  Action: 1  //  Reward: 10  // Next_state: 15\n",
      "\n",
      "Accumulated_reward: -1.0  //  Mean_reward: -0.08333333333333333\n",
      "Episode reached objective\n",
      "\n",
      "============================\n",
      "Episode: 86 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:02  //  Action: 3  //  Reward: -1  // Next_state: 2\n",
      "Step:03  //  Action: 3  //  Reward: -1  // Next_state: 2\n",
      "Step:04  //  Action: 2  //  Reward: -1  // Next_state: 2\n",
      "Step:05  //  Action: 1  //  Reward: -1  // Next_state: 3\n",
      "Step:06  //  Action: 1  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -7.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 87 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -2.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 88 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 9\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 13\n",
      "Step:04  //  Action: 0  //  Reward: -1  // Next_state: 14\n",
      "Step:05  //  Action: 1  //  Reward: -1  // Next_state: 13\n",
      "Step:06  //  Action: 0  //  Reward: -1  // Next_state: 13\n",
      "Step:07  //  Action: 0  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -8.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 89 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 9\n",
      "Step:03  //  Action: 1  //  Reward: -1  // Next_state: 13\n",
      "Step:04  //  Action: 0  //  Reward: -1  // Next_state: 13\n",
      "Step:05  //  Action: 3  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -6.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 90 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -2.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 91 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 9\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 13\n",
      "Step:04  //  Action: 0  //  Reward: -1  // Next_state: 14\n",
      "Step:05  //  Action: 2  //  Reward: -1  // Next_state: 13\n",
      "Step:06  //  Action: 0  //  Reward: -1  // Next_state: 14\n",
      "Step:07  //  Action: 1  //  Reward: -1  // Next_state: 13\n",
      "Step:08  //  Action: 3  //  Reward: -1  // Next_state: 13\n",
      "Step:09  //  Action: 0  //  Reward: -1  // Next_state: 9\n",
      "Step:10  //  Action: 1  //  Reward: -1  // Next_state: 8\n",
      "Step:11  //  Action: 1  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -12.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 92 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -2.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 93 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 3  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -3.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 94 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 0  //  Reward: -1  // Next_state: 9\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:04  //  Action: 3  //  Reward: -1  // Next_state: 9\n",
      "Step:05  //  Action: 2  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -6.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 95 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 2\n",
      "Step:02  //  Action: 2  //  Reward: -1  // Next_state: 6\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 7\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 7\n",
      "\n",
      "============================\n",
      "Episode: 96 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 0  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -2.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 97 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 3  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:04  //  Action: 0  //  Reward: -1  // Next_state: 9\n",
      "Step:05  //  Action: 1  //  Reward: -1  // Next_state: 8\n",
      "Step:06  //  Action: 2  //  Reward: -1  // Next_state: 12\n",
      "\n",
      "Accumulated_reward: -7.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 12\n",
      "\n",
      "============================\n",
      "Episode: 98 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 2  //  Reward: -1  // Next_state: 0\n",
      "Step:01  //  Action: 3  //  Reward: -1  // Next_state: 1\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -4.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Episode: 99 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 3  //  Reward: -1  // Next_state: 1\n",
      "Step:01  //  Action: 1  //  Reward: -1  // Next_state: 1\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 5\n",
      "\n",
      "Accumulated_reward: -3.0  //  Mean_reward: -1.0\n",
      "Episode ended because terminal state on: 5\n",
      "\n",
      "============================\n",
      "Mean accumulated reward: -5.45\n",
      "Episode_objective_reached: 85\n",
      "============================\n",
      "\n",
      "============================\n",
      "Best_episode: 85 // Epsilon: 0.5\n",
      "============================\n",
      "Step:00  //  Action: 1  //  Reward: -1  // Next_state: 4\n",
      "Step:01  //  Action: 2  //  Reward: -1  // Next_state: 8\n",
      "Step:02  //  Action: 1  //  Reward: -1  // Next_state: 9\n",
      "Step:03  //  Action: 2  //  Reward: -1  // Next_state: 13\n",
      "Step:04  //  Action: 0  //  Reward: -1  // Next_state: 14\n",
      "Step:05  //  Action: 2  //  Reward: -1  // Next_state: 13\n",
      "Step:06  //  Action: 3  //  Reward: -1  // Next_state: 14\n",
      "Step:07  //  Action: 1  //  Reward: -1  // Next_state: 10\n",
      "Step:08  //  Action: 3  //  Reward: -1  // Next_state: 14\n",
      "Step:09  //  Action: 1  //  Reward: -1  // Next_state: 10\n",
      "Step:10  //  Action: 2  //  Reward: -1  // Next_state: 14\n",
      "Step:11  //  Action: 1  //  Reward: 10  // Next_state: 15\n",
      "\n",
      "Accumulated_reward: -1.0  //  Mean_reward: -0.08333333333333333 // Objective_reached: 85\n"
     ]
    }
   ],
   "source": [
    "# ============ FROZEN_LAKE =================\n",
    "\n",
    "t_acc_reward = 0\n",
    "best_acc_reward = acc_reward[0]\n",
    "best_data = [ev_act[0], ev_reward[0], ev_state[0]]\n",
    "best_ep_info = [0,ev_epsilon[0]]\n",
    "\n",
    "\n",
    "for i in range(len(ev_state)):\n",
    "    print(f'\\n============================\\nEpisode: {i} // Epsilon: {ev_epsilon[i]}\\n============================')\n",
    "    for j in range(len(ev_state[i])):\n",
    "        s = ''\n",
    "        if j < 10:\n",
    "            s = '0'\n",
    "        print(\"Step:\" + s + f'{j}  //  Action: {ev_act[i][j]}  //  Reward: {ev_reward[i][j]}  // Next_state: {ev_state[i][j]}')\n",
    "    \n",
    "    print(f'\\nAccumulated_reward: {acc_reward[i]}  //  Mean_reward: {acc_reward[i]/(j+1)}')\n",
    "    \n",
    "    if acc_reward[i] > best_acc_reward:\n",
    "        best_acc_reward = acc_reward[i]\n",
    "        best_data = [ev_act[i], ev_reward[i], ev_state[i]]\n",
    "        best_ep_info = [i, ev_epsilon[i]]\n",
    "    \n",
    "    if j == max_steps-1:\n",
    "        print(f'Episode ended because it took too long')\n",
    "    elif ev_state[i][j] != 15:\n",
    "        print(f'Episode ended because terminal state on: {ev_state[i][j]}')\n",
    "    else:\n",
    "        print(f'Episode reached objective')\n",
    "\n",
    "    t_acc_reward += acc_reward[i]\n",
    "    \n",
    "print(f'\\n============================\\nMean accumulated reward: {t_acc_reward/(i+1)}')\n",
    "print(f'Episode_objective_reached: {ep_ob_reached}\\n============================')\n",
    "\n",
    "print(f'\\n============================\\nBest_episode: {best_ep_info[0]} // Epsilon: {best_ep_info[1]}\\n============================')\n",
    "for j in range(len(best_data[0])):\n",
    "    s = ''\n",
    "    if j < 10:\n",
    "        s = '0'\n",
    "    print(\"Step:\" + s + f'{j}  //  Action: {best_data[0][j]}  //  Reward: {best_data[1][j]}  // Next_state: {best_data[2][j]}')\n",
    "    \n",
    "print(f'\\nAccumulated_reward: {best_acc_reward}  //  Mean_reward: {best_acc_reward/(j+1)} // Objective_reached: {ep_ob_reached}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13441f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(acc_reward, label=\"Recompensa por episodio\", alpha=0.7)\n",
    "\n",
    "if len(acc_reward) > window:\n",
    "    mv = np.convolve(acc_reward, np.ones(window)/window, mode='valid')\n",
    "    plt.plot(range(window-1, window-1+len(mv)), mv, label=f\"Media móvil ({window})\")\n",
    "\n",
    "plt.xlabel(\"Episodios\")\n",
    "plt.ylabel(\"Recompensa\")\n",
    "plt.title(\"Aprendizaje con Q-Learning - LunarLander\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead854cc",
   "metadata": {},
   "source": [
    "# Recompensas personalizadas\n",
    "\n",
    "Aunque el entorno Frozen Lake tiene un parámetro para indicar recompensas cuando se producen ciertos estados (alcanzar la meta, caerse en un agujero, o llegar a un bloque de hielo), es posible que queramos definir otras recompensas dado un cierto estado. Por ejemplo, penalizar una acción que no produce un cambio de estado (en este caso seria intentar salirse del mapa). Para ello es necesario implementar nuestro propio \"wrapper\" de recompensas. Aunque para el caso que hemos planteado, en lugar de realizar un wrapper sobre la recompensa, es posible aplicarlo de la misma manera sobre el método step.\n",
    "\n",
    "La última versión de Gymnasium te permite hacerlo. Aquí puedes consultar la información: [Documentación RewardWrapper](https://gymnasium.farama.org/tutorials/gymnasium_basics/implementing_custom_wrappers/#inheriting-from-gymnasium-rewardwrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fd988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import Wrapper\n",
    "\n",
    "class FrozenLakePenaltyWrapper(Wrapper):\n",
    "    def __init__(self, env):\n",
    "\n",
    "    #Para este caso, debes de wrappear el metodo step\n",
    "    def step(self, action):\n",
    "        #Falta código\n",
    "        return obs, reward, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13793e45-035e-40e8-94f5-acae7abcf738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea el entorno FrozenLake indicandole los parámetros. Para empezar, que el parámetro is_slippery = False.\n",
    "env = gym.make(\"FrozenLake-v1\", is_slippery=False, map_name=\"4x4\", reward_schedule=(10,0,0), render_mode=\"human\")\n",
    "\n",
    "# Aplicar el wrapper\n",
    "env = #Falta código\n",
    "\n",
    "\n",
    "##Define el número de episodios y comprueba que el wrapper funciona ;) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe8bd19-caf5-4ce0-99e6-80ab2e9c6115",
   "metadata": {},
   "source": [
    "# Acciones personalizadas\n",
    "\n",
    "Similarmente a la personalización de las recompensas, podemos personalizar las acciones que se realizan en el entorno. FrozenLake tiene el modo \"is_slippery\" que básicamente lo simula repite una acción con una probabilidad dado un estado (si es bloque de hielo).\n",
    "\n",
    "Sin embargo, otra de las funcionalidades útiles que tiene, es que permite discretizar un conjunto de acciones continuo. Consulta la documentación e prueba el ejemplo que aparece en la documentación para entenderlo. Aquí puedes consultar la información: [Documentación ActionWrapper](https://gymnasium.farama.org/tutorials/gymnasium_basics/implementing_custom_wrappers/#inheriting-from-gymnasium-actionwrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1569840-9c40-4384-8acb-c744667e018b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a232cca-39ff-4148-bb4e-6d867fa0a49b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
